{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"John like to watch movies\",\n",
    "         \"Mary likes to play football\",\n",
    "         \"John likes to watch football games but does not like to play football\",\n",
    "         \"Both John and Mary like to play video games\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John like to watch movies', 'Mary likes to play football', 'John likes to watch football games but does not like to play football', 'Both John and Mary like to play video games']\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"you've\", 'all', \"you'd\", \"mightn't\", 'such', \"she's\", 'if', \"don't\", 'itself', 's', 'has', 'does', \"shan't\", 'is', 'above', 'once', 'of', \"won't\", 'he', 'there', \"couldn't\", 'just', 'y', 'very', 'against', 'should', 'because', \"shouldn't\", 'how', 'my', 'we', \"that'll\", 'until', 'each', 'herself', 'they', 'whom', 'then', \"needn't\", 'in', 'don', 'having', 'than', \"you're\", 'ma', 'over', 'again', 'no', \"should've\", 'shan', 'the', 'hadn', 're', 'wouldn', 'some', \"hadn't\", 'his', 'few', 'them', 'but', 'd', 'under', 'these', 'during', 'here', 'same', 'i', 'both', \"aren't\", 'it', 'from', 'their', 'be', 'a', 'him', 'out', 'yourself', 'what', \"mustn't\", 'about', 'himself', 'can', 'down', 'its', 'wasn', 'themselves', 'which', 'your', 'most', 'won', 'up', 'needn', 'yours', 'her', 'an', 'into', 'was', 'when', 'those', 'aren', 'shouldn', 'that', 'now', 'you', 'couldn', 'isn', 'as', 'too', 'why', 'our', 'are', 'mightn', \"wasn't\", 'had', 'and', 'who', 'to', \"wouldn't\", 'been', 'being', 'through', 'further', \"didn't\", 'before', 'm', 'so', 'theirs', \"haven't\", 'for', 'will', 'more', 'me', 'ours', 'didn', 'not', \"isn't\", 'haven', 'myself', 'this', 'ourselves', \"hasn't\", 'll', 've', 'yourselves', \"it's\", 'have', 'at', 'on', 'any', 'only', 'own', 'o', 'weren', 'off', 'do', 'where', 't', \"you'll\", 'did', 'other', 'hers', 'nor', 'or', 'mustn', 'below', 'am', 'were', 'after', \"weren't\", 'she', 'doesn', 'between', 'by', 'with', 'doing', 'ain', 'while', \"doesn't\", 'hasn'}\n"
     ]
    }
   ],
   "source": [
    "# display all the english stop words\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "print(english_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to remove all the stop words\n",
    "def remove_stopwords(sentence):\n",
    "    # tokenize the sentence\n",
    "    word_tokens = nltk.word_tokenize(sentence)\n",
    "    print(word_tokens)\n",
    "    \n",
    "    # remove all the stop words from the text\n",
    "    cleaned_text = [w.lower() for w in word_tokens if(w not in english_stopwords)]\n",
    "    return(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ram', 'and', 'Shyam', 'likes', 'to', 'play']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ram', 'shyam', 'likes', 'play']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords('Ram and Shyam likes to play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a vocabulary and remove all the duplicate words\n",
    "def build_vocabulary(sentences):\n",
    "    words = []\n",
    "    \n",
    "    # loop through each and every sentences\n",
    "    for x in sentences:\n",
    "        # call the function to remove all the stop words\n",
    "        words_new = remove_stopwords(x)\n",
    "        words.extend(words_new)\n",
    "        \n",
    "    # keep all the tokenized words and sort it\n",
    "    sorted_words = list(sorted(words))\n",
    "    return(sorted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John', 'like', 'to', 'watch', 'movies']\n",
      "['Mary', 'likes', 'to', 'play', 'football']\n",
      "['John', 'likes', 'to', 'watch', 'football', 'games', 'but', 'does', 'not', 'like', 'to', 'play', 'football']\n",
      "['Both', 'John', 'and', 'Mary', 'like', 'to', 'play', 'video', 'games']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = build_vocabulary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a bag of array of the frequency count\n",
    "def bag_of_count_vectors(sentence,words):\n",
    "    # remove all the stop words\n",
    "    sent = remove_stopwords(sentence)\n",
    "    \n",
    "    # create an array for the bag of vectors\n",
    "    bag = np.zeros(len(words))\n",
    "    \n",
    "    # To check if the word is present in the vocabulary\n",
    "    for pol in sent:\n",
    "        for i, word in enumerate(words):\n",
    "            if(word == pol):\n",
    "                bag[i] += 1\n",
    "    \n",
    "    # return an array for the bag of words vector\n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John', 'like', 'to', 'watch', 'movies']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_count_vectors('John like to watch movies',vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
