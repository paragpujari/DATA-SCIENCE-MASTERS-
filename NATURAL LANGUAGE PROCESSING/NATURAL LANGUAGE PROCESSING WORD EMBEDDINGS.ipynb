{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary libraries\n",
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['the glass of milk',\n",
    "     'the glass of juice',\n",
    "     'the cup of tea',\n",
    "    'I am a good boy',\n",
    "     'I am a good developer',\n",
    "     'understand the meaning of words',\n",
    "     'your videos are good',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the glass of milk', 'the glass of juice', 'the cup of tea', 'I am a good boy', 'I am a good developer', 'understand the meaning of words', 'your videos are good']\n"
     ]
    }
   ],
   "source": [
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary size\n",
    "voc_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Representation of Words\n",
    "\n",
    "It provides the index position of all the words present in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1476, 432, 6521, 9579], [1476, 432, 6521, 3505], [1476, 8880, 6521, 1741], [4804, 9616, 9623, 946, 4779], [4804, 9616, 9623, 946, 4669], [3742, 1476, 1393, 6521, 4321], [9238, 9889, 2272, 946]]\n"
     ]
    }
   ],
   "source": [
    "onehot_representation = [ one_hot(words,voc_size) for words in sentence]\n",
    "print(onehot_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 1476  432 6521 9579]\n",
      " [   0    0    0    0 1476  432 6521 3505]\n",
      " [   0    0    0    0 1476 8880 6521 1741]\n",
      " [   0    0    0 4804 9616 9623  946 4779]\n",
      " [   0    0    0 4804 9616 9623  946 4669]\n",
      " [   0    0    0 3742 1476 1393 6521 4321]\n",
      " [   0    0    0    0 9238 9889 2272  946]]\n"
     ]
    }
   ],
   "source": [
    "# To create an Embedding matrix from the onehot representation of the words\n",
    "sent_length = 8\n",
    "embedding_sequence = pad_sequences(onehot_representation, padding = 'pre', maxlen = sent_length)\n",
    "print(embedding_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the input into the embedding layer\n",
    "model = Sequential()\n",
    "# add the embedding layer\n",
    "model.add(Embedding(voc_size, 10, input_length = sent_length))\n",
    "# compile the model with 'adam' optimizer\n",
    "model.compile('adam','mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 10)             100000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,000\n",
      "Trainable params: 100,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.01057332 -0.04814214 -0.02897564 -0.03757374  0.0347049\n",
      "   -0.0467235  -0.02903759  0.0253568  -0.01989452  0.01646716]\n",
      "  [ 0.02886364  0.00994092  0.02528677  0.00210773 -0.02625689\n",
      "   -0.00399375  0.00477371 -0.03638518  0.02842586 -0.01994228]\n",
      "  [ 0.01544688  0.02574969 -0.01064975 -0.04521927  0.04926241\n",
      "    0.03771789  0.02472155 -0.01034353 -0.04056023  0.01480242]\n",
      "  [-0.04104323  0.01115636  0.01871915 -0.00247991  0.00847461\n",
      "    0.01002359  0.02648214  0.03928815 -0.00729351 -0.00727483]]\n",
      "\n",
      " [[-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.01057332 -0.04814214 -0.02897564 -0.03757374  0.0347049\n",
      "   -0.0467235  -0.02903759  0.0253568  -0.01989452  0.01646716]\n",
      "  [ 0.02886364  0.00994092  0.02528677  0.00210773 -0.02625689\n",
      "   -0.00399375  0.00477371 -0.03638518  0.02842586 -0.01994228]\n",
      "  [ 0.01544688  0.02574969 -0.01064975 -0.04521927  0.04926241\n",
      "    0.03771789  0.02472155 -0.01034353 -0.04056023  0.01480242]\n",
      "  [ 0.0047278  -0.04165522 -0.04345323 -0.03723117  0.006772\n",
      "    0.02612105 -0.03256889  0.01845479 -0.03277402  0.02357833]]\n",
      "\n",
      " [[-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.01057332 -0.04814214 -0.02897564 -0.03757374  0.0347049\n",
      "   -0.0467235  -0.02903759  0.0253568  -0.01989452  0.01646716]\n",
      "  [ 0.03898654  0.03273899  0.0209846  -0.01364188 -0.02572676\n",
      "   -0.02271334  0.03962663  0.04022285 -0.01497569 -0.00545186]\n",
      "  [ 0.01544688  0.02574969 -0.01064975 -0.04521927  0.04926241\n",
      "    0.03771789  0.02472155 -0.01034353 -0.04056023  0.01480242]\n",
      "  [-0.01458539  0.04505987 -0.03558273 -0.00786446 -0.04387933\n",
      "    0.02169937 -0.0301231   0.0228903   0.04194507  0.0424258 ]]\n",
      "\n",
      " [[-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [ 0.00673719  0.0064928   0.0063846   0.04629464 -0.03690346\n",
      "    0.0311612  -0.03142069  0.04968891  0.02552023  0.02372826]\n",
      "  [ 0.04104136  0.03740444  0.01427862  0.04104569 -0.00016121\n",
      "    0.0356778  -0.0328287  -0.04413691  0.02018522 -0.01142297]\n",
      "  [-0.00412567 -0.04334491 -0.01958925  0.011569    0.0255844\n",
      "    0.04555606  0.01958164  0.02128695 -0.00406941 -0.00108329]\n",
      "  [-0.01485224  0.01764401  0.04767283 -0.02031567  0.01705793\n",
      "    0.00761032 -0.00616225  0.01257118 -0.04066923  0.00699099]\n",
      "  [ 0.02567407  0.01190481  0.0463816  -0.04141861  0.04200932\n",
      "   -0.04606208 -0.0110855   0.01156082 -0.01107676 -0.03180847]]\n",
      "\n",
      " [[-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [ 0.00673719  0.0064928   0.0063846   0.04629464 -0.03690346\n",
      "    0.0311612  -0.03142069  0.04968891  0.02552023  0.02372826]\n",
      "  [ 0.04104136  0.03740444  0.01427862  0.04104569 -0.00016121\n",
      "    0.0356778  -0.0328287  -0.04413691  0.02018522 -0.01142297]\n",
      "  [-0.00412567 -0.04334491 -0.01958925  0.011569    0.0255844\n",
      "    0.04555606  0.01958164  0.02128695 -0.00406941 -0.00108329]\n",
      "  [-0.01485224  0.01764401  0.04767283 -0.02031567  0.01705793\n",
      "    0.00761032 -0.00616225  0.01257118 -0.04066923  0.00699099]\n",
      "  [-0.00040516  0.03210083 -0.04874873  0.01350787  0.02936233\n",
      "    0.02592056  0.03344387  0.01480076  0.02072034  0.01054163]]\n",
      "\n",
      " [[-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [ 0.02682303 -0.02848804  0.03207384 -0.03914285 -0.04841733\n",
      "    0.04763195  0.03171339  0.03590618 -0.03100873 -0.02663521]\n",
      "  [-0.01057332 -0.04814214 -0.02897564 -0.03757374  0.0347049\n",
      "   -0.0467235  -0.02903759  0.0253568  -0.01989452  0.01646716]\n",
      "  [-0.02861202  0.0470657  -0.03785245 -0.02255967 -0.03503797\n",
      "   -0.04694244 -0.00030404 -0.03556328  0.04095932 -0.04245062]\n",
      "  [ 0.01544688  0.02574969 -0.01064975 -0.04521927  0.04926241\n",
      "    0.03771789  0.02472155 -0.01034353 -0.04056023  0.01480242]\n",
      "  [ 0.02728703 -0.0151205  -0.00696223  0.01600612 -0.03967147\n",
      "    0.03624226 -0.03065242  0.02905606 -0.01615919 -0.02231598]]\n",
      "\n",
      " [[-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419\n",
      "   -0.00317445  0.01617844  0.04520619  0.02794706  0.04464606]\n",
      "  [ 0.04637853 -0.03792425 -0.0307148  -0.02982342 -0.02121744\n",
      "    0.04827383  0.04589448 -0.01946727 -0.02282872  0.00492307]\n",
      "  [-0.00819407 -0.00491625 -0.02625743  0.02204776 -0.00557958\n",
      "    0.04715006  0.0477893   0.02605745  0.03661479 -0.01100699]\n",
      "  [ 0.01676705  0.04462085  0.01563926 -0.02901131 -0.00873633\n",
      "   -0.04994829  0.03853263  0.0009194   0.01245898 -0.03858997]\n",
      "  [-0.01485224  0.01764401  0.04767283 -0.02031567  0.01705793\n",
      "    0.00761032 -0.00616225  0.01257118 -0.04066923  0.00699099]]]\n"
     ]
    }
   ],
   "source": [
    "# Get the vectorized representation of the words\n",
    "print(model.predict(embedding_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0 1476  432 6521 9579]\n"
     ]
    }
   ],
   "source": [
    "print(embedding_sequence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_input'), name='embedding_input', description=\"created by layer 'embedding_input'\"), but it was called on an input with incompatible shape (None,).\n",
      "[[-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419 -0.00317445\n",
      "   0.01617844  0.04520619  0.02794706  0.04464606]\n",
      " [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419 -0.00317445\n",
      "   0.01617844  0.04520619  0.02794706  0.04464606]\n",
      " [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419 -0.00317445\n",
      "   0.01617844  0.04520619  0.02794706  0.04464606]\n",
      " [-0.00670875  0.01133387  0.02488199 -0.01436546 -0.02233419 -0.00317445\n",
      "   0.01617844  0.04520619  0.02794706  0.04464606]\n",
      " [-0.01057332 -0.04814214 -0.02897564 -0.03757374  0.0347049  -0.0467235\n",
      "  -0.02903759  0.0253568  -0.01989452  0.01646716]\n",
      " [ 0.02886364  0.00994092  0.02528677  0.00210773 -0.02625689 -0.00399375\n",
      "   0.00477371 -0.03638518  0.02842586 -0.01994228]\n",
      " [ 0.01544688  0.02574969 -0.01064975 -0.04521927  0.04926241  0.03771789\n",
      "   0.02472155 -0.01034353 -0.04056023  0.01480242]\n",
      " [-0.04104323  0.01115636  0.01871915 -0.00247991  0.00847461  0.01002359\n",
      "   0.02648214  0.03928815 -0.00729351 -0.00727483]]\n"
     ]
    }
   ],
   "source": [
    "# Get the vectorized representation of all the onehot values in form of dimensions\n",
    "print(model.predict(embedding_sequence[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
