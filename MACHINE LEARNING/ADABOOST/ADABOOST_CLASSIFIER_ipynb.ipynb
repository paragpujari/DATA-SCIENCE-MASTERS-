{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eOBdFD9_Lf7g"
      },
      "outputs": [],
      "source": [
        "# import all the necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "data = pd.read_csv('/content/iris.csv')"
      ],
      "metadata": {
        "id": "nDDWefvwMc76"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYleG4z3Mimo",
        "outputId": "a7938fa1-207a-4daa-bcae-97a81d5c26fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width    species\n",
            "0             5.1          3.5           1.4          0.2     setosa\n",
            "1             4.9          3.0           1.4          0.2     setosa\n",
            "2             4.7          3.2           1.3          0.2     setosa\n",
            "3             4.6          3.1           1.5          0.2     setosa\n",
            "4             5.0          3.6           1.4          0.2     setosa\n",
            "..            ...          ...           ...          ...        ...\n",
            "145           6.7          3.0           5.2          2.3  virginica\n",
            "146           6.3          2.5           5.0          1.9  virginica\n",
            "147           6.5          3.0           5.2          2.0  virginica\n",
            "148           6.2          3.4           5.4          2.3  virginica\n",
            "149           5.9          3.0           5.1          1.8  virginica\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display the first five rows of the dataset\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYMBUNLVMlfB",
        "outputId": "92cdf457-b6f8-4aec-8da2-75a4cee5e901"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width species\n",
            "0           5.1          3.5           1.4          0.2  setosa\n",
            "1           4.9          3.0           1.4          0.2  setosa\n",
            "2           4.7          3.2           1.3          0.2  setosa\n",
            "3           4.6          3.1           1.5          0.2  setosa\n",
            "4           5.0          3.6           1.4          0.2  setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# display the last five rows of the dataset\n",
        "print(data.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbNNZA5gMq4l",
        "outputId": "330d6d8c-b142-4eff-80fd-0573e6c8de40"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width    species\n",
            "145           6.7          3.0           5.2          2.3  virginica\n",
            "146           6.3          2.5           5.0          1.9  virginica\n",
            "147           6.5          3.0           5.2          2.0  virginica\n",
            "148           6.2          3.4           5.4          2.3  virginica\n",
            "149           5.9          3.0           5.1          1.8  virginica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of the dataset\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liMPEDEAMwMf",
        "outputId": "5f1eaf11-0f4b-409b-acec-a78dfae16aab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# divide the dataset into independent and dependent variables\n",
        "data_x = data.iloc[:,0:4].values\n",
        "print(data_x)\n",
        "\n",
        "data_y = data.iloc[:,4].values\n",
        "print(data_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17lv6rCCM1C9",
        "outputId": "4458973c-f7b7-4f7b-ce37-ad6dec060010"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n",
            "['setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa' 'setosa'\n",
            " 'setosa' 'setosa' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'versicolor' 'versicolor' 'versicolor' 'versicolor'\n",
            " 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'virginica' 'virginica' 'virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "lab = LabelEncoder()\n",
        "\n",
        "# perform the label encoding of the model\n",
        "\n",
        "data_y = lab.fit_transform(data_y)\n",
        "\n",
        "print(data_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdOn0AdCNVH6",
        "outputId": "4feab09b-872a-42eb-fe4a-2579a77c9453"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# divide the dataset into training and testing data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(data_x, data_y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "GdalHRjZNtTk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PYEhx99ODtc",
        "outputId": "af2c96a0-324c-4cee-b0d6-b24a1fc620d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.4 3.1 5.5 1.8]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [5.  2.  3.5 1. ]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [5.1 3.5 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [6.  3.  4.8 1.8]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.7 3.  5.  1.7]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [4.6 3.2 1.4 0.2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTD8mdm9OHGm",
        "outputId": "5bcacad4-b71b-4ab4-d82d-bf790133d6e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.8 2.8 5.1 2.4]\n",
            " [6.  2.2 4.  1. ]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.  3.4 1.6 0.4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rvHx0wmOKIU",
        "outputId": "6d437d50-5fd9-4ede-eeb6-10bcf7cfc4ce"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 1 0 2 2 1 0 1 1 1 2 0 2 0 0 1 2 2 2 2 1 2 1 1 2 2 2 2 1 2 1 0 2 1 1 1 1\n",
            " 2 0 0 2 1 0 0 1 0 2 1 0 1 2 1 0 2 2 2 2 0 0 2 2 0 2 0 2 2 0 0 2 0 0 0 1 2\n",
            " 2 0 0 0 1 1 0 0 1 0 2 1 2 1 0 2 0 2 0 0 2 0 2 1 1 1 2 2 1 1 0 1 2 2 0 1 1\n",
            " 1 1 0 0 0 2 1 2 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**APPLY ADA BOOST CLASSIFIER ALGORITHM**"
      ],
      "metadata": {
        "id": "LeB9vhahON_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# create the object for Aba Boost Classifier\n",
        "\n",
        "bada = AdaBoostClassifier()\n",
        "\n",
        "\n",
        "# train the model\n",
        "bada.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "VjEpccnSOUk_",
        "outputId": "9452f937-51d9-468d-c302-dc7ad8fc9924"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict the model\n",
        "pred_y = bada.predict(X_test)"
      ],
      "metadata": {
        "id": "v_zlZPlKOm4P"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxWTg43eOwKc",
        "outputId": "af1afd3d-5da7-4df6-b504-7dc149c4879c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 1 0 2 0 2 0 1 1 1 1 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ACCURACY OF THE MODEL**"
      ],
      "metadata": {
        "id": "KPkPoW_oO4FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "ac = accuracy_score(Y_test, pred_y)\n",
        "\n",
        "print('Accuracy of the model is:', (ac * 100.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0BykkvIO7YP",
        "outputId": "56378ada-f1d8-4782-8910-12ff98e4bd34"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model is: 96.66666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(pred_y, Y_test)\n",
        "\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9gJi1yPPIez",
        "outputId": "601a721a-c344-497a-c8a9-54609f479c2d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[11  0  0]\n",
            " [ 0 13  1]\n",
            " [ 0  0  5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the confusion matrix in form of heatmap\n",
        "sns.heatmap(cm, annot = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "wveAa9oCPR7E",
        "outputId": "dd376810-4e41-4242-e684-6aba0be6fc97"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr = classification_report(Y_test, pred_y)\n",
        "\n",
        "print(cr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvK-7q0zPY_5",
        "outputId": "cab416ae-faae-4ab3-baa1-cbd7c8e866c2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        11\n",
            "           1       0.93      1.00      0.96        13\n",
            "           2       1.00      0.83      0.91         6\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.98      0.94      0.96        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    }
  ]
}